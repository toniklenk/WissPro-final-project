{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e32a8c2-9497-47e2-b432-ee240cfbf865",
   "metadata": {},
   "source": [
    "# CreditCardApproval MachineLearning Diana Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06799917-827e-489c-852e-9d463b94f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    MinMaxScaler,\n",
    "    FunctionTransformer,\n",
    "    TargetEncoder,\n",
    "    label_binarize,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    make_scorer,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    DetCurveDisplay,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    cross_validate,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    RepeatedStratifiedKFold,\n",
    ")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.base import clone\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "credit_approval = fetch_ucirepo(id=27)\n",
    "\n",
    "X = credit_approval.data.features\n",
    "y = credit_approval.data.targets\n",
    "df = credit_approval.data.original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeabffd-9971-45e1-848e-0dea4e7e10c9",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c339378-ffc0-49ec-b896-ae5fe95039a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Maybe add some more advanced techniques from here later: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d95c81-67e0-4ac0-849b-84ca3aafb3dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### feature engineering: mixed numerical categorical feature space (this is old code, use fully numerical feature space for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc8830-54a0-4154-8ce9-62b5d0610158",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"), OneHotEncoder(drop=\"first\")\n",
    "        ),\n",
    "        [\"A1\"],\n",
    "    ),\n",
    "    (make_pipeline(SimpleImputer(strategy=\"median\"), MinMaxScaler()), [\"A2\"]),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            FunctionTransformer(lambda col: col.mask(col != \"u\", \"non-u\")),\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder(drop=\"first\"),\n",
    "        ),\n",
    "        [\"A4\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            FunctionTransformer(\n",
    "                lambda col: col.replace(\n",
    "                    {\n",
    "                        \"v\": \"v\",\n",
    "                        \"h\": \"h\",\n",
    "                        \"bb\": \"other\",\n",
    "                        \"ff\": \"other\",\n",
    "                        \"j\": \"other\",\n",
    "                        \"z\": \"other\",\n",
    "                        \"dd\": \"other\",\n",
    "                        \"n\": \"other\",\n",
    "                        \"o\": \"other\",\n",
    "                    }\n",
    "                )\n",
    "            ),\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder(drop=\"first\"),\n",
    "        ),\n",
    "        [\"A7\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            FunctionTransformer(\n",
    "                lambda col: col.replace({\"g\": \"g\", \"s\": \"non-g\", \"p\": \"non-g\"})\n",
    "            ),\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder(drop=\"first\"),\n",
    "        ),\n",
    "        [\"A13\"],\n",
    "    ),\n",
    "    (\n",
    "        \"test\",\n",
    "        make_pipeline(\n",
    "            FunctionTransformer(np.log1p),\n",
    "            SimpleImputer(strategy=\"median\"),\n",
    "            MinMaxScaler(),\n",
    "        ),\n",
    "        [\"A11\", \"A14\", \"A15\"],\n",
    "    ),\n",
    "    # continuous default\n",
    "    (\n",
    "        make_pipeline(\n",
    "            MinMaxScaler(),\n",
    "        ),\n",
    "        [\"A3\", \"A8\"],\n",
    "    ),\n",
    "    # categorical default\n",
    "    (\n",
    "        make_pipeline(\n",
    "            OneHotEncoder(drop=\"first\"),\n",
    "        ),\n",
    "        [\"A9\", \"A10\", \"A12\"],\n",
    "    ),\n",
    "    # remove: A5, A6\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060d907-a4f9-430f-a653-50460ce0fa85",
   "metadata": {},
   "source": [
    "### feature engineering: fully numerical feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd886ae7-87c5-4abf-b044-cd8d402286e7",
   "metadata": {},
   "source": [
    "#### variant 1: include A7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd77624-5f2f-4c45-b370-b1fb543bd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_tweaker_include_a7 = make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder(sparse_output=False, drop=\"first\"),\n",
    "        ),\n",
    "        [\"A1\", \"A9\", \"A10\", \"A12\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            FunctionTransformer(lambda col: label_binarize(col, classes=[\"u\"])),\n",
    "        ),\n",
    "        [\"A4\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            FunctionTransformer(lambda col: label_binarize(col, classes=[\"g\"])),\n",
    "        ),\n",
    "        [\"A5\"],\n",
    "    ),\n",
    "    (make_pipeline(TargetEncoder(), SimpleImputer(strategy=\"median\")), [\"A6\", \"A7\"]),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            FunctionTransformer(lambda col: label_binarize(col, classes=[\"g\"])),\n",
    "        ),\n",
    "        [\"A13\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(FunctionTransformer(np.log1p), SimpleImputer(strategy=\"median\")),\n",
    "        [\"A2\", \"A3\", \"A8\", \"A11\", \"A14\", \"A15\"],\n",
    "    ),\n",
    "    # leave everything else untouched\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4511e-a7e1-4c00-b176-4917dad40113",
   "metadata": {},
   "source": [
    "#### variant 2: exclude A7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd20158-21e8-4065-8fec-3459e3fba9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_tweaker_exclude_a7 = make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder(sparse_output=False, drop=\"first\"),\n",
    "        ),\n",
    "        [\"A1\", \"A9\", \"A10\", \"A12\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            FunctionTransformer(lambda col: label_binarize(col, classes=[\"u\"])),\n",
    "        ),\n",
    "        [\"A4\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            FunctionTransformer(lambda col: label_binarize(col, classes=[\"g\"])),\n",
    "        ),\n",
    "        [\"A5\"],\n",
    "    ),\n",
    "    (make_pipeline(TargetEncoder(), SimpleImputer(strategy=\"median\")), [\"A6\"]),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            FunctionTransformer(lambda col: label_binarize(col, classes=[\"g\"])),\n",
    "        ),\n",
    "        [\"A13\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(FunctionTransformer(np.log1p), SimpleImputer(strategy=\"median\")),\n",
    "        [\"A2\", \"A3\", \"A8\", \"A11\", \"A14\", \"A15\"],\n",
    "    ),\n",
    "    # leave everything else untouched\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f3c3e-b374-454b-9d3d-000a1efc0c8b",
   "metadata": {},
   "source": [
    "### feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799bcf8-0695-4c2f-8192-cd499c11260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e38b62-218e-484f-9da2-f3c15fc26e47",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcea5af-53eb-4a15-a3ad-8dabd3b5db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_pca = PCA(n_components=0.99, svd_solver=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6ec2c-94cc-4f2c-9e90-ebe24bdc3b74",
   "metadata": {},
   "source": [
    "### put together pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102041fb-48a7-4961-817c-1f0aee3105a8",
   "metadata": {},
   "source": [
    "#### feature engineering pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f55276-f482-4af9-8f91-30017b31ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipe = make_pipeline(column_tweaker_exclude_a7, column_scaler, column_pca)\n",
    "preprocessing_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a3a234-3399-4829-9b8a-15728929e7a0",
   "metadata": {},
   "source": [
    "#### feature engineering pipeline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9fd33-e042-41d4-a138-1efd96751281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "In which different formats do we need the data for different classifiers ?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d60e5-0d7c-4692-afbd-73c65ee1431e",
   "metadata": {},
   "source": [
    "# train test validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acca771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values.ravel()\n",
    "y[y == \"+\"] = 1\n",
    "y[y == \"-\"] = 0\n",
    "y = y.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4b63a-cd58-4142-9143-402eb35b3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocessed = preprocessing_pipe.fit_transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f29ad6-2c49-4498-9504-3bb81e14080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_validate, y_train, y_test_validate = train_test_split(\n",
    "    X_preprocessed, y, test_size=0.1, random_state=seed\n",
    ")\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b23a9-60c5-48ff-b330-5f2ca0fceac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_validate, y_test, y_validate = train_test_split(\n",
    "    X_test_validate, y_test_validate, test_size=0.5\n",
    ")\n",
    "(X_test.shape, y_test.shape), (X_validate.shape, y_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test, y_train_test = np.concatenate((X_train, X_test)), np.concatenate(\n",
    "    (y_train, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f56c04-0ce7-4987-a3d3-50a8f2827fda",
   "metadata": {},
   "source": [
    "# train & optimise different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50f7789",
   "metadata": {},
   "source": [
    "On what to optimize ?\n",
    "\n",
    "The task is o predict, if, given the different parameters, access to a credit card is denied or granted.\n",
    "\n",
    "- The worst case would be to give access to a position that is obvious fraud (False Positive). Cost: The owner looses money.\n",
    "- Rejecting access to a legit position (False Negative) would be inconvenient, since someone wouldn't be able to draw his money, but we consider it less of a problem than a False Positive.\n",
    "\n",
    "- Obviously, a True Positive would be giving someone his money while a True Negative would be denying fraud.\n",
    "\n",
    "\n",
    "\n",
    "In summary, we primarily optimize for the False Positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a3e53",
   "metadata": {},
   "source": [
    "Additional metrics:\n",
    "- The dataset is balanced therefore classificatino accuracy is a meaningfull metrix as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51514b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    \"Precision\": make_scorer(precision_score, pos_label=1),\n",
    "    \"Accuracy\": make_scorer(accuracy_score),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc42b8",
   "metadata": {},
   "source": [
    "How to compare classifiers ?\n",
    "- Plot learning curves.\n",
    "- Compare missclassified examples.\n",
    "- Compare robustness in different CV-splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9934e100",
   "metadata": {},
   "source": [
    "Next, we compare the performance of a variety of common ML classifiers. Since we are relativey naive to which classifiers could work, we try a diverse set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ddd8c",
   "metadata": {},
   "source": [
    "##### Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_scores(base, grid):\n",
    "    # Precision\n",
    "    # Baseline\n",
    "    mean = base[\"test_Precision\"].mean()\n",
    "    std = base[\"test_Precision\"].std()\n",
    "    plt.axhline(\n",
    "        y=0,\n",
    "        color=\"grey\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    plt.plot(mean, 0, \"o\", color=\"black\", markersize=10, label=f\"Mean = {mean:.2f}\")\n",
    "    plt.plot(\n",
    "        [mean - std, mean + std],\n",
    "        [0, 0],\n",
    "        color=\"black\",\n",
    "        linewidth=1.5,\n",
    "        label=f\"STD = {std:.2f}\",\n",
    "    )\n",
    "    plt.vlines(\n",
    "        [mean - std, mean + std], ymin=-0.1, ymax=0.1, color=\"black\", linewidth=1.5\n",
    "    )\n",
    "\n",
    "    # GridSearch\n",
    "    mean = grid[\"test_Precision\"].mean()\n",
    "    std = grid[\"test_Precision\"].std()\n",
    "    plt.axhline(\n",
    "        y=0,\n",
    "        color=\"grey\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    plt.plot(mean, 0, \"o\", color=\"magenta\", markersize=10, label=f\"Mean = {mean:.2f}\")\n",
    "    plt.plot(\n",
    "        [mean - std, mean + std],\n",
    "        [0, 0],\n",
    "        color=\"magenta\",\n",
    "        linewidth=1.5,\n",
    "        label=f\"STD = {std:.2f}\",\n",
    "    )\n",
    "    plt.vlines(\n",
    "        [mean - std, mean + std], ymin=-0.1, ymax=0.1, color=\"magenta\", linewidth=1.5\n",
    "    )\n",
    "\n",
    "    # Accuracy\n",
    "    # Baseline\n",
    "    mean = base[\"test_Accuracy\"].mean()\n",
    "    std = base[\"test_Accuracy\"].std()\n",
    "    plt.axhline(\n",
    "        y=1,\n",
    "        color=\"grey\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    plt.plot(mean, 1, \"o\", color=\"black\", markersize=10, label=f\"Mean = {mean:.2f}\")\n",
    "    plt.plot(\n",
    "        [mean - std, mean + std],\n",
    "        [1, 1],\n",
    "        color=\"black\",\n",
    "        linewidth=1.5,\n",
    "        label=f\"STD = {std:.2f}\",\n",
    "    )\n",
    "    plt.vlines(\n",
    "        [mean - std, mean + std],\n",
    "        ymin=1 - 0.1,\n",
    "        ymax=1 + 0.1,\n",
    "        color=\"black\",\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "    # GridSearch\n",
    "    mean = grid[\"test_Accuracy\"].mean()\n",
    "    std = grid[\"test_Accuracy\"].std()\n",
    "    plt.axhline(\n",
    "        y=1,\n",
    "        color=\"grey\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    plt.plot(mean, 1, \"o\", color=\"magenta\", markersize=10, label=f\"Mean = {mean:.2f}\")\n",
    "    plt.plot(\n",
    "        [mean - std, mean + std],\n",
    "        [1, 1],\n",
    "        color=\"magenta\",\n",
    "        linewidth=1.5,\n",
    "        label=f\"STD = {std:.2f}\",\n",
    "    )\n",
    "    plt.vlines(\n",
    "        [mean - std, mean + std],\n",
    "        ymin=1 - 0.1,\n",
    "        ymax=1 + 0.1,\n",
    "        color=\"magenta\",\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "    plt.ylabel(\"\")\n",
    "    plt.ylim(-0.8, 1.8)\n",
    "    plt.yticks(ticks=[0, 1], labels=[\"Precision\", \"Accuracy\"])\n",
    "\n",
    "    plt.xlim(0.70, 0.95)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.suptitle(\"Mean and std of 10-fold CV\")\n",
    "    plt.title(\"baseline (black) vs estimator from GridSearch (magenta))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a6986",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis\n",
    "\n",
    "Parameters:\n",
    "'priors' : The default value estimates the class proportions from the training set. Since our dataset with n<1000 is relatively small, class proportions might be slightly skewed leading to a suboptimal estimation from the training data ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7cb62a",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee61067",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_base_cv = cross_validate(\n",
    "    LinearDiscriminantAnalysis(), X_train_test, y_train_test, cv=10, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe8b5d",
   "metadata": {},
   "source": [
    "### GridSeach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb50b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"priors\": [\n",
    "        [0.05, 0.95],\n",
    "        [0.1, 0.9],\n",
    "        [0.15, 0.85],\n",
    "        [0.2, 0.8],\n",
    "        [0.25, 0.75],\n",
    "        [0.3, 0.7],\n",
    "        [0.35, 0.65],\n",
    "        [0.4, 0.6],\n",
    "        [0.45, 0.55],\n",
    "        [0.5, 0.5],\n",
    "        [0.55, 0.45],\n",
    "        [0.6, 0.4],\n",
    "        [0.65, 0.35],\n",
    "        [0.7, 0.3],\n",
    "        [0.75, 0.25],\n",
    "        [0.8, 0.2],\n",
    "        [0.85, 0.15],\n",
    "        [0.9, 0.1],\n",
    "        [0.95, 0.05],\n",
    "    ]\n",
    "}\n",
    "lda_grid = GridSearchCV(\n",
    "    estimator=LinearDiscriminantAnalysis(),\n",
    "    param_grid=param_grid,\n",
    "    cv=10,\n",
    "    scoring=scoring,\n",
    "    refit=\"Accuracy\",\n",
    ")\n",
    "lda_grid.fit(X_train_test, y_train_test)\n",
    "lda_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_grid_cv = cross_validate(\n",
    "    lda_grid.best_estimator_, X_train_test, y_train_test, cv=10, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_scores(lda_base_cv, lda_grid_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f93ae",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ece6c",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_base_cv = cross_validate(\n",
    "    QuadraticDiscriminantAnalysis(), X_train_test, y_train_test, cv=10, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb012ba",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"priors\": [\n",
    "        [0.05, 0.95],\n",
    "        [0.1, 0.9],\n",
    "        [0.15, 0.85],\n",
    "        [0.2, 0.8],\n",
    "        [0.25, 0.75],\n",
    "        [0.3, 0.7],\n",
    "        [0.35, 0.65],\n",
    "        [0.4, 0.6],\n",
    "        [0.45, 0.55],\n",
    "        [0.5, 0.5],\n",
    "        [0.55, 0.45],\n",
    "        [0.6, 0.4],\n",
    "        [0.65, 0.35],\n",
    "        [0.7, 0.3],\n",
    "        [0.75, 0.25],\n",
    "        [0.8, 0.2],\n",
    "        [0.85, 0.15],\n",
    "        [0.9, 0.1],\n",
    "        [0.95, 0.05],\n",
    "    ]\n",
    "}\n",
    "\n",
    "qda_grid = GridSearchCV(\n",
    "    estimator=QuadraticDiscriminantAnalysis(),\n",
    "    param_grid=param_grid,\n",
    "    cv=10,\n",
    "    scoring=scoring,\n",
    "    refit=\"Accuracy\",\n",
    ")\n",
    "qda_grid.fit(X_train_test, y_train_test)\n",
    "qda_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_grid_cv = cross_validate(\n",
    "    qda_grid.best_estimator_, X_train_test, y_train_test, cv=10, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_scores(qda_base_cv, qda_grid_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023151e-ca9e-41be-afc1-ed802739ecdb",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c46f24",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base_cv = cross_validate(\n",
    "    RandomForestClassifier(), X_train_test, y_train_test, cv=10, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66aa25",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best values, so we don't need to run excessive GridSearch again\n",
    "param_grid = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"max_depth\": [None],\n",
    "    \"min_samples_split\": [10],\n",
    "    \"min_samples_leaf\": [4],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"bootstrap\": [True],\n",
    "    \"criterion\": [\"entropy\"],\n",
    "}\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300, 400, 500],\n",
    "#     'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "#     'min_samples_split': [2, 5, 10, 15, 20],\n",
    "#     'min_samples_leaf': [1, 2, 4, 6, 8, 10],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'bootstrap': [True, False],\n",
    "#     'criterion': ['gini', 'entropy']\n",
    "# }\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    scoring=scoring,\n",
    "    param_grid=param_grid,\n",
    "    verbose=1,\n",
    "    cv=10,\n",
    "    refit=\"Accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_cv = cross_validate(\n",
    "    rf_grid.best_estimator_, X_train_test, y_train_test, cv=10, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afc18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_scores(rf_base_cv, rf_grid_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2a4f1-8dde-419a-96f6-ed631df72891",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91fd58d",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_base_cv = cross_validate(\n",
    "    KNeighborsClassifier(), X_train_test, y_train_test, cv=10, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d1f43",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c292b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_neighbors\": [5, 10, 15],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"p\": [1, 2],\n",
    "}\n",
    "\n",
    "kn_grid = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    scoring=scoring,\n",
    "    param_grid=param_grid,\n",
    "    verbose=1,\n",
    "    cv=10,\n",
    "    refit=\"Accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "kn_grid.fit(X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_grid_cv = cross_validate(\n",
    "    kn_grid.best_estimator_, X_train_test, y_train_test, cv=10, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_scores(kn_base_cv, kn_grid_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb0f0f-6c9a-473a-aace-fa6076341e38",
   "metadata": {},
   "source": [
    "## Adaboost\n",
    "A ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d62231",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff83fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_base_cv = cross_validate(\n",
    "    AdaBoostClassifier(n_estimators=100, algorithm=\"SAMME\", random_state=0),\n",
    "    X_train_test,\n",
    "    y_train_test,\n",
    "    cv=10,\n",
    "    scoring=scoring,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad1eb4",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6accc6dc",
   "metadata": {},
   "source": [
    "#### Parameter descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b91878",
   "metadata": {},
   "source": [
    "##### 1. **Number of Estimators (`n_estimators`)**:\n",
    "   - **Description**: This is the number of weak learners (or base estimators) to be used in the boosting process. Higher values can lead to better performance but also increase the risk of overfitting.\n",
    "   - **Typical Range**: `[50, 100, 200, 300, 400, 500]`\n",
    "\n",
    "##### 2. **Learning Rate (`learning_rate`)**:\n",
    "   - **Description**: This shrinks the contribution of each weak learner by multiplying their weights. A lower learning rate requires a higher number of estimators.\n",
    "   - **Typical Range**: `[0.001, 0.01, 0.1, 0.5, 1.0]`\n",
    "\n",
    "##### 3. **Base Estimator (`base_estimator`)**:\n",
    "   - **Description**: The weak learner to be used. Typically, a decision tree classifier is used, but this can be replaced by other classifiers.\n",
    "   - **Typical Range**:\n",
    "     - For Decision Trees: `DecisionTreeClassifier(max_depth=1)` (default), or vary `max_depth`, `min_samples_split`, and `min_samples_leaf`.\n",
    "     - Other weak learners: `DecisionTreeClassifier`, `SVM`, etc.\n",
    "\n",
    "##### 4. **Algorithm (`algorithm`)**:\n",
    "   - **Description**: The algorithm used to choose the weights for the weak learners.\n",
    "   - **Options**: `['SAMME', 'SAMME.R']`\n",
    "   - **Explanation**:\n",
    "     - `SAMME.R` uses the probability estimates and generally performs better, especially when `base_estimator` can output class probabilities.\n",
    "     - `SAMME` is a more traditional approach.\n",
    "\n",
    "##### 5. **Random State (`random_state`)**:\n",
    "   - **Description**: Controls the randomness of the bootstrapping of the samples used when building trees. It’s important for reproducibility.\n",
    "   - **Typical Range**: `[None, 42, 1]` (using fixed seeds like `42` can help reproduce results)\n",
    "\n",
    "##### 6. **Max Depth of Base Estimator (`max_depth`)**:\n",
    "   - **Description**: Depth of the decision tree if it is used as the base estimator. Shallow trees prevent overfitting.\n",
    "   - **Typical Range**: `[1, 2, 3, 4, 5]`\n",
    "\n",
    "##### 7. **Min Samples Split (`min_samples_split`)** (if decision tree is used as the base estimator):\n",
    "   - **Description**: The minimum number of samples required to split an internal node.\n",
    "   - **Typical Range**: `[2, 5, 10]`\n",
    "\n",
    "##### 8. **Min Samples Leaf (`min_samples_leaf`)** (if decision tree is used as the base estimator):\n",
    "   - **Description**: The minimum number of samples required to be at a leaf node.\n",
    "   - **Typical Range**: `[1, 2, 5, 10]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check if all these methods always categorize the same, or different samples wrong. If the later is the case, this would motivate using a ensemble method to balance strengths and weaknesses of different classifiers.\n",
    "\n",
    "Maybe building some ensemble method that combines a (gradient boosted) dewcicion tree for the categorical variables with something like SVM for the continuous data.\n",
    "\n",
    "This would obviate the need for target encoding of A6 and A7 and poosible better handle the many binary variables in the dataset. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c6b4c",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"algorithm\": [\"SAMME\"],\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"learning_rate\": [0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "# bigger version:\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'learning_rate': [0.01, 0.1, 1.0],\n",
    "#     'algorithm': ['SAMME', 'SAMME.R'],\n",
    "#     'base_estimator_max_depth': [1, 2, 3],\n",
    "#     'base_estimator_min__samples_split': [2, 5],\n",
    "#     'base_estimator_min__samples_leaf': [1, 2]\n",
    "# }\n",
    "\n",
    "ada_grid = GridSearchCV(\n",
    "    AdaBoostClassifier(),\n",
    "    param_grid,\n",
    "    cv=10,\n",
    "    scoring=scoring,\n",
    "    refit=\"Accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "ada_grid.fit(X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d44bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_grid_cv = cross_validate(\n",
    "    ada_grid.best_estimator_, X_train_test, y_train_test, cv=10, scoring=scoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5136c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_scores(ada_base_cv, ada_grid_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46730dc-1550-4525-979a-37c40540ed27",
   "metadata": {},
   "source": [
    "# model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181b711",
   "metadata": {},
   "source": [
    "## compare scores on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_grid\n",
    "qda_grid\n",
    "rf_grid\n",
    "kn_grid\n",
    "ada_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12391ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(np.nan, index=(\"LDA\",\"QDA\",\"RandomForest\", \"KNeighbors\",\"AdaBoost\"), columns=(\"accuracy\", \"precision\"))\n",
    "\n",
    "for i, model in enumerate((lda_grid, qda_grid, rf_grid, kn_grid, ada_grid)):\n",
    "    y_pred = model.best_estimator_.predict(X_validate)\n",
    "    scores.iloc[i,0], scores.iloc[i,1] = accuracy_score(y_validate, y_pred), precision_score(y_validate, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "axes[0].bar(scores.index, scores.accuracy, width=.33)\n",
    "axes[0].set_ylim(.75, .9)\n",
    "axes[0].set_title(\"Accuracy\")\n",
    "\n",
    "\n",
    "axes[1].bar(scores.index, scores.precision, width=.6)\n",
    "axes[1].set_ylim(.75, .9)\n",
    "axes[1].set_title(\"Precision\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab56e4e9",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61aa67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "#RocCurveDisplay.from_estimator(lda_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "RocCurveDisplay.from_estimator(qda_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "RocCurveDisplay.from_estimator(rf_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "RocCurveDisplay.from_estimator(kn_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "RocCurveDisplay.from_estimator(ada_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "plt.title(\"ROC curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390e146",
   "metadata": {},
   "source": [
    "## Precision Recall Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "#PrecisionRecallDisplay.from_estimator(lda_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "PrecisionRecallDisplay.from_estimator(qda_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "PrecisionRecallDisplay.from_estimator(rf_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "PrecisionRecallDisplay.from_estimator(kn_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "PrecisionRecallDisplay.from_estimator(ada_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "plt.title(\"precision recall curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b956685b",
   "metadata": {},
   "source": [
    "## DET curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa282dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AdaBoost has best accuracy/precision, KN has best ROC-AUC, QDA has second best ROC-AUC\"\"\"\n",
    "\n",
    "ax = plt.subplot()\n",
    "#DetCurveDisplay.from_estimator(lda_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "DetCurveDisplay.from_estimator(qda_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "#DetCurveDisplay.from_estimator(rf_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "DetCurveDisplay.from_estimator(kn_grid.best_estimator_, X_validate, y_validate, ax=ax)\n",
    "DetCurveDisplay.from_estimator(ada_grid.best_estimator_, X_validate, y_validate, ax=ax);\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0bae8",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_num = np.where(y_train == \"+\", 1, 0)\n",
    "y_validate_num = np.where(y_validate == \"+\", 1, 0)\n",
    "\n",
    "rf_num = search_rf.best_estimator_.fit(X_train, y_num)\n",
    "knn_num = search_knn.best_estimator_.fit(X_train, y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a326a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DetCurveDisplay.from_predictions(y_validate, rf_best.predict)\n",
    "# Get prediction probabilities\n",
    "rf_best = search_rf.best_estimator_\n",
    "# probabilities = rf_best.predict_proba(X_validate)\n",
    "# print(\"Prediction Probabilities:\\n\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eec04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class predictions (optional)\n",
    "predictions_rf = rf_num.predict(X_validate)\n",
    "print(\"Class Predictions:\\n\", predictions_rf)\n",
    "\n",
    "predictions_knn = knn_num.predict(X_validate)\n",
    "print(\"Class Predictions:\\n\", predictions_knn)\n",
    "\n",
    "# DetCurveDisplay.from_predictions(y_validate_num, predictions_rf)\n",
    "# DetCurveDisplay.from_predictions(y_validate_num, predictions_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fab6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evauation\n",
    "\n",
    "# Since classes are balanced, accuracy is the correct evaluation metric.\n",
    "\n",
    "# Plot ROC for different hyperparameters\n",
    "\n",
    "# above: plot full results of grid search to showcase effects of different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec7d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
