{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3d0056-58d5-4232-ba83-5b68dc52d0ea",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8f4762a43e050a0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Credit Card Application Approval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8673ac-27d3-46ec-9eb1-dafac68106e5",
   "metadata": {},
   "source": [
    "This project is concerned with a dataset dealing with credit card applications. Based on the feature given in the dataset the task is to predict if a person's request for a credit card is approved (or denied)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a88537-4794-467f-b913-365f21230aa7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42103e2b306de1bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba586fd-ca75-49d8-b391-63550dd52cc8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62dbccd60b2622b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Information on the \"Credit Approval\" dataset from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/) can be found here: \n",
    "\n",
    "* Download URL: https://archive.ics.uci.edu/static/public/27/credit+approval.zip\n",
    "* DOI: https://doi.org/10.24432/C5FS30\n",
    "* Dataset creators: J. R. Quinlan\n",
    "* License: Creative Commons Attribution 4.0 International ([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553e710-6765-4c4b-aa58-7457dd3e1239",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tasks\n",
    "\n",
    "Below you can find a summary of the single subtasks you are required to work on during this project.\n",
    "\n",
    "### Exploratory Data Analysis (EDA)\n",
    "\n",
    "Perform a thorough analysis of the data. Preferably, use well-established tools from the Python package eco-system such as, e.g., [Pandas](https://pandas.pydata.org/docs), [Matplotlib](https://matplotlib.org/stable/index.html) / [Seaborn](https://seaborn.pydata.org/). Another helpful tool is [Ydata Profiling](https://docs.profiling.ydata.ai/).\n",
    "\n",
    "Things to consider for the analysis:\n",
    "\n",
    "* Visualise as much as possible. Make your visualisation easy to understand by using, e.g., labels for the axes or titles.\n",
    "* Take into account differences regarding the features such as categorical vs. continuous.\n",
    "* Consider correlations between different features. Also analyse how single features are correlated with the target.\n",
    "* Check for missing values.\n",
    "\n",
    "### Machine Learning (ML)\n",
    "\n",
    "Apply machine learning models of your choice to solve this classification task. Again, use appropriate tools such as those found in the [Scikit-Learn](https://scikit-learn.org/stable/index.html) library. You may also consider using tools such as [XGBoost](https://xgboost.readthedocs.io/en/latest/python/) or a neural network based on [PyTorch](https://pytorch.org/docs/stable/index.html) or [TensorFlow](https://www.tensorflow.org/api_docs).\n",
    "\n",
    "Things to consider:\n",
    "\n",
    "* Make sure to split your data into train and test data before using any ML model.\n",
    "* Think about how to handle missing values and how to deal with features of different type (categorical and continuous). This also pertains to techniques such as feature encoding (e.g., refer to [this link form the Scikit-Learn documentation](https://scikit-learn.org/stable/modules/preprocessing.html)) and feature engineering (e.g., frequency / count encoding or target encoding for categorical features).\n",
    "* Use data processing pipelines to have a clean way of preparing your data for a particular ML model. Note that different types of models (e.g., Logistic Regression vs. Gradient Boosted Trees) may require different preparation steps for the data.\n",
    "* Choose a proper metric (or several if appropriate) to evaluate a given model.\n",
    "* Optimise the hyper-parameters of your ML models to achieve the best possible performance on the data.\n",
    "* Compare different ML models.\n",
    "\n",
    "### Comments\n",
    "\n",
    "Document your workflow appropriately. If you choose to work with Juypter Notebooks this can be achieved by having dedicated notebooks for different parts of the project (e.g., EDA and ML models). Within a single notebook use sections and comments to document important decisions and the intent of your analysis. \n",
    "\n",
    "Your notebooks will look much cleaner and become a lot easier to comprehend if you avoid code duplication. That is, before using many code snippets that only differ slightly, consider finding a common abstraction and have a single dedicated place for this code (e.g., inside a function or a class) that enables easy reuse. It is oftentimes suitable to move code to a Python module. This module can then be readily imported in your Jupyter notebooks.\n",
    "\n",
    "It should be possible to (easily) reproduce your results by re-executing your notebooks.\n",
    "\n",
    "If you are working in groups it must be obvious which group member has conducted which part of the work. Hence, please make sure to add annotations inside the docstring of functions / classes or appriate comments in the sections of your Jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b19329-d912-495b-82d4-13d16fbbefe4",
   "metadata": {},
   "source": [
    "## Presentation of Results\n",
    "\n",
    "### Oral Presentation\n",
    "\n",
    "In the presentation your are meant to present the workflow during the project as well as the main results (in total 20 - 40 minutes for *all* members of the group combined, *not* per group member). Outline which tools you have used (e.g., Pandas, Scikit-Learn) and how you have approached the data to arrive at certain results. Also discuss the choice / usage of your ML models in relation to the EDA.\n",
    "\n",
    "Choose a suitable medium such as ML-office-alike slides or Jupyter notebooks. If you are using the latter, please pay special attention to conciseness and a clean structure. Comprehensibly prepare your results by using, e.g., flow-charts for representing workflows and figures / tables for summarizing quantitative results. Please pay special attention to legiblity of axes labels, titles and legends in plots as well to colors and line types.\n",
    "\n",
    "### Comments\n",
    "\n",
    "If you are working in groups it must be obvious from your presentation which group member has conducted which part of the work. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc0e54-49e9-4a04-b234-1adc43a99a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from dataprep.eda import create_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7de4ba-232e-44b7-848c-a5c248bff2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f5a4e-49c0-4673-91c6-42c4e0af0b1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# fetch dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4764a7d-44fe-4fcb-b090-ef00f4e58f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_approval = fetch_ucirepo(id=27) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b650945-d69d-42d4-becb-441e99cbb0c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# data (as pandas dataframes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae3f82-cf56-4085-9243-fbfe38696320",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit_approval.data.features\n",
    "y = credit_approval.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feafe1b2-64ca-4a12-a91d-7058a99c4119",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227fe6e7-77cf-4018-9bf4-7b70d5cefb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(credit_approval.metadata) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c50b2d-4a9a-44fc-a7f3-ff2b3933a34d",
   "metadata": {},
   "source": [
    "# variable information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a60b03-12fd-47be-bc07-ba549c934fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_approval.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef6f836-bc3e-419b-865c-30b682ae23be",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "The grade is to 100% determined by the presentation. \n",
    "\n",
    "In case of a group work *every group member will get an individual grade*. It therefore must be obvious from your presentation which group member is responsible for which part of the work. It is also possible for group members to for example conduct different quantitative analyses of the data (by considering different ML models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc9521-8bc9-4c98-9914-2e08700a11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Usefool tools\n",
    "- pipelines\n",
    "- feature union\n",
    "- \n",
    "\n",
    "- confusion matrix\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8934acb-38ae-43d0-b943-75caed1f8272",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f79b4-641b-4818-8dfe-f85e88a37e26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset general overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b42fe9-e71c-4739-9168-fa0ce3503695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4f3c5-774f-426a-bf8f-084364ff5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c64c3-f232-4a4c-8afd-4de8de31d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with Marcels toolbox\n",
    "create_report(X.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f43d05-6294-445e-9592-2b870778ddf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f101b98-9a6b-49a2-8bfb-3cb2ede148e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Histrogramm of all idividual features on a grid\n",
    "- Maybe remove some sparse values.\n",
    "- How much shared information between different features ?\n",
    "- How many values in each respective combination of all categorical types ?\n",
    "\n",
    "\n",
    "Information measurement of single features (is this usefull if we have so many features?)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96e8cd-4cef-4d90-baaf-341b90c169c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_approval.variables[credit_approval.variables.type=='Categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c036f1aa-a455-40d9-aedc-a9fc48684a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(nrows=2, ncols=5, figsize = (10,10))\n",
    "X.A13.hist(ax=ax[0][0])\n",
    "X.A12.hist(ax=ax[0][1])\n",
    "X.A10.hist(ax=ax[0][2])\n",
    "X.A9.hist(ax=ax[0][3])\n",
    "X.A7.hist(ax=ax[0][4])\n",
    "X.A6.hist(ax=ax[1][0])\n",
    "X.A5.hist(ax=ax[1][1])\n",
    "X.A4.hist(ax=ax[1][2])\n",
    "X.A1.hist(ax=ax[1][3])\n",
    "ax[1][4].remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551fdd4e-48db-4f40-87a5-1aaa69b04bea",
   "metadata": {},
   "source": [
    "Are there any obvious strong dependencies ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b6c17-86cc-40f7-b636-03e4cbcaccc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c3464-0b48-41fd-9bc9-ae6981d5f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- No obvious strong correlations. \n",
    "- Standardize features.\n",
    "\n",
    "Further analysis:\n",
    "- Principal component analysis.\n",
    "\n",
    "\n",
    "- Outlier removal/replacement with mean/median (gaussian distribution?)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba783e-b938-4fc7-b7ac-ed21015ab413",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c29a9-6606-455d-9456-556caca561f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(X._get_numeric_data().dropna())\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262c5ba-1525-420e-a15d-79aadf18d7fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## NaN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf7ed0-47e7-42b4-a549-447fed92ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Drop rows with much missing data\n",
    "- Data imputation for rest of NaN's, look at distribution of column values to decide to replace with median/mean.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc87cc-981e-42f3-8f04-5c806ac4e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of NaN's per feature\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f37b5b-3ce0-4f70-8c67-1833737aef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total share of rows with any value NaN\n",
    "(X.isna().sum(axis=1)>0).sum()/690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c5d918-43a3-4f91-92e3-313c333cff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How strongly do NaN's occur together ? (How much data would we loose if just completely drop any line with a NaN ?)\n",
    "X.isna().sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1d5ea-b71e-428c-afa1-d7338359122d",
   "metadata": {},
   "source": [
    "Simply dropping every line with any value NaN only removes ~5% of data.\\\n",
    "Which is a loss we are willing to take in the first run. We later come back and try different methods of dropping NaN to optimized performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01cc767-a00a-4ec5-a522-4b024ec2053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b890a26-7c94-453b-9a3d-302edb4ea937",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bdc72-042e-41fc-986f-6a2330591cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Approaches for combining categorial / numerical data:\n",
    "- Seperate classifiers, e.g. decicion tree + regressor\n",
    "- Encoding of categorical data.\n",
    "\n",
    "Feature selection:\n",
    "- Forward / backward feature selection\n",
    "\n",
    "Models:\n",
    "- Regression\n",
    "- XGBoost\n",
    "- Neural network\n",
    "- Random forest with missing data imputation\n",
    "- LightGBM\n",
    "\n",
    "Evaluating classifier performance:\n",
    "- Cross validation\n",
    "- Model evaluation metrics (FDR, TPR), precicion/recall, ROC_AUC\n",
    "- Graphics were all models are in comparison\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883d5fb-69c3-4002-bd63-7e9f125d01a2",
   "metadata": {},
   "source": [
    "## Encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16121767-dabd-4d26-bd1e-51a6d683efce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c15157-9902-47f6-97fc-f86f6de7cb2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## baseline classifier: 82% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0940c-c04e-45f4-b6db-fbd47b4c53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef69a4-2a25-41f9-97ab-e69714fc5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc0eff-24e6-4199-b721-25874be9e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = credit_approval.data.targets.replace({'+':1,'-':0})\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a678a0-4d14-47f4-9331-5f19fb010f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline(\n",
    "    steps = [\n",
    "        #(\"encoder\", ce.OneHotEncoder()),\n",
    "        ('xgb', xgb.XGBRegressor(objective=\"reg:linear\", random_state=42))\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c9d24-1a24-4666-9002-94fb8e054d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit_approval.data.features\n",
    "y = targets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33)#, random_state=42)\n",
    "\n",
    "#xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n",
    "\n",
    "pipe.fit(X_train._get_numeric_data(), y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test._get_numeric_data())\n",
    "\n",
    "mse=mean_squared_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95314d8b-9145-4f5c-afbd-7c9e3994de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
