{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3d0056-58d5-4232-ba83-5b68dc52d0ea",
   "metadata": {
    "id": "2f3d0056-58d5-4232-ba83-5b68dc52d0ea",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8f4762a43e050a0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Credit Card Application Approval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8673ac-27d3-46ec-9eb1-dafac68106e5",
   "metadata": {
    "id": "fa8673ac-27d3-46ec-9eb1-dafac68106e5"
   },
   "source": [
    "This project is concerned with a dataset dealing with credit card applications. Based on the feature given in the dataset the task is to predict if a person's request for a credit card is approved (or denied)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a88537-4794-467f-b913-365f21230aa7",
   "metadata": {
    "id": "d3a88537-4794-467f-b913-365f21230aa7",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42103e2b306de1bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba586fd-ca75-49d8-b391-63550dd52cc8",
   "metadata": {
    "id": "7ba586fd-ca75-49d8-b391-63550dd52cc8",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62dbccd60b2622b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Information on the \"Credit Approval\" dataset from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/) can be found here:\n",
    "\n",
    "* Download URL: https://archive.ics.uci.edu/static/public/27/credit+approval.zip\n",
    "* DOI: https://doi.org/10.24432/C5FS30\n",
    "* Dataset creators: J. R. Quinlan\n",
    "* License: Creative Commons Attribution 4.0 International ([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1c259-5034-40f4-b306-cfbcc44a0623",
   "metadata": {
    "id": "7553e710-6765-4c4b-aa58-7457dd3e1239"
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74717155-d31b-4020-8af5-89a8194105bb",
   "metadata": {
    "id": "7553e710-6765-4c4b-aa58-7457dd3e1239"
   },
   "source": [
    "Below you can find a summary of the single subtasks you are required to work on during this project.\n",
    "\n",
    "### Exploratory Data Analysis (EDA)\n",
    "\n",
    "Perform a thorough analysis of the data. Preferably, use well-established tools from the Python package eco-system such as, e.g., [Pandas](https://pandas.pydata.org/docs), [Matplotlib](https://matplotlib.org/stable/index.html) / [Seaborn](https://seaborn.pydata.org/). Another helpful tool is [Ydata Profiling](https://docs.profiling.ydata.ai/).\n",
    "\n",
    "Things to consider for the analysis:\n",
    "\n",
    "* Visualise as much as possible. Make your visualisation easy to understand by using, e.g., labels for the axes or titles.\n",
    "* Take into account differences regarding the features such as categorical vs. continuous.\n",
    "* Consider correlations between different features. Also analyse how single features are correlated with the target.\n",
    "* Check for missing values.\n",
    "\n",
    "### Machine Learning (ML)\n",
    "\n",
    "Apply machine learning models of your choice to solve this classification task. Again, use appropriate tools such as those found in the [Scikit-Learn](https://scikit-learn.org/stable/index.html) library. You may also consider using tools such as [XGBoost](https://xgboost.readthedocs.io/en/latest/python/) or a neural network based on [PyTorch](https://pytorch.org/docs/stable/index.html) or [TensorFlow](https://www.tensorflow.org/api_docs).\n",
    "\n",
    "Things to consider:\n",
    "\n",
    "* Make sure to split your data into train and test data before using any ML model.\n",
    "* Think about how to handle missing values and how to deal with features of different type (categorical and continuous). This also pertains to techniques such as feature encoding (e.g., refer to [this link form the Scikit-Learn documentation](https://scikit-learn.org/stable/modules/preprocessing.html)) and feature engineering (e.g., frequency / count encoding or target encoding for categorical features).\n",
    "* Use data processing pipelines to have a clean way of preparing your data for a particular ML model. Note that different types of models (e.g., Logistic Regression vs. Gradient Boosted Trees) may require different preparation steps for the data.\n",
    "* Choose a proper metric (or several if appropriate) to evaluate a given model.\n",
    "* Optimise the hyper-parameters of your ML models to achieve the best possible performance on the data.\n",
    "* Compare different ML models.\n",
    "\n",
    "### Comments\n",
    "\n",
    "Document your workflow appropriately. If you choose to work with Juypter Notebooks this can be achieved by having dedicated notebooks for different parts of the project (e.g., EDA and ML models). Within a single notebook use sections and comments to document important decisions and the intent of your analysis.\n",
    "\n",
    "Your notebooks will look much cleaner and become a lot easier to comprehend if you avoid code duplication. That is, before using many code snippets that only differ slightly, consider finding a common abstraction and have a single dedicated place for this code (e.g., inside a function or a class) that enables easy reuse. It is oftentimes suitable to move code to a Python module. This module can then be readily imported in your Jupyter notebooks.\n",
    "\n",
    "It should be possible to (easily) reproduce your results by re-executing your notebooks.\n",
    "\n",
    "If you are working in groups it must be obvious which group member has conducted which part of the work. Hence, please make sure to add annotations inside the docstring of functions / classes or appriate comments in the sections of your Jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd8180-cba2-4abb-81b3-8a54bedd3656",
   "metadata": {
    "id": "a2b19329-d912-495b-82d4-13d16fbbefe4",
    "tags": []
   },
   "source": [
    "## Presentation of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096cb63-2ac6-436d-a6d7-24fd29b09b1a",
   "metadata": {
    "id": "a2b19329-d912-495b-82d4-13d16fbbefe4"
   },
   "source": [
    "### Oral Presentation\n",
    "\n",
    "In the presentation your are meant to present the workflow during the project as well as the main results (in total 20 - 40 minutes for *all* members of the group combined, *not* per group member). Outline which tools you have used (e.g., Pandas, Scikit-Learn) and how you have approached the data to arrive at certain results. Also discuss the choice / usage of your ML models in relation to the EDA.\n",
    "\n",
    "Choose a suitable medium such as ML-office-alike slides or Jupyter notebooks. If you are using the latter, please pay special attention to conciseness and a clean structure. Comprehensibly prepare your results by using, e.g., flow-charts for representing workflows and figures / tables for summarizing quantitative results. Please pay special attention to legiblity of axes labels, titles and legends in plots as well to colors and line types.\n",
    "\n",
    "### Comments\n",
    "\n",
    "If you are working in groups it must be obvious from your presentation which group member has conducted which part of the work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef6f836-bc3e-419b-865c-30b682ae23be",
   "metadata": {
    "id": "cef6f836-bc3e-419b-865c-30b682ae23be"
   },
   "source": [
    "## Grading\n",
    "\n",
    "The grade is to 100% determined by the presentation.\n",
    "\n",
    "In case of a group work *every group member will get an individual grade*. It therefore must be obvious from your presentation which group member is responsible for which part of the work. It is also possible for group members to for example conduct different quantitative analyses of the data (by considering different ML models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7f1ee-d620-4eb3-9063-56bfbae1e272",
   "metadata": {},
   "source": [
    "# import & fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6bee4-a442-4ce5-a4a7-9ca0e6e191c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "error",
     "timestamp": 1702555193137,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "64dc0e54-49e9-4a04-b234-1adc43a99a07",
    "outputId": "fd766e21-193a-4168-812d-ba8b78d6bf1b"
   },
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.base import clone\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7de4ba-232e-44b7-848c-a5c248bff2a9",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1702555193137,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "9e7de4ba-232e-44b7-848c-a5c248bff2a9"
   },
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4764a7d-44fe-4fcb-b090-ef00f4e58f62",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1702555193138,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "f4764a7d-44fe-4fcb-b090-ef00f4e58f62"
   },
   "outputs": [],
   "source": [
    "credit_approval = fetch_ucirepo(id=27)\n",
    "\n",
    "X = credit_approval.data.features\n",
    "y = credit_approval.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8934acb-38ae-43d0-b943-75caed1f8272",
   "metadata": {
    "id": "d8934acb-38ae-43d0-b943-75caed1f8272",
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2362f845-6e56-4b53-9fb8-7c34af56a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_approval.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b42fe9-e71c-4739-9168-fa0ce3503695",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1702555193140,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "d9b42fe9-e71c-4739-9168-fa0ce3503695"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4f3c5-774f-426a-bf8f-084364ff5033",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1702555193140,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "d8e4f3c5-774f-426a-bf8f-084364ff5033"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81edbfc-1617-4b70-b279-61cac1a3f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c64c3-f232-4a4c-8afd-4de8de31d00d",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1702555193140,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "1e8c64c3-f232-4a4c-8afd-4de8de31d00d"
   },
   "outputs": [],
   "source": [
    "# replace with Marcels toolbox\n",
    "profile = ProfileReport(X, title = \"Profiling Report\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89183e01-64a0-45fb-b64f-23be48a0b8de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361d606-2e60-4a9d-9f6d-9a5734b4151f",
   "metadata": {},
   "source": [
    "A4 and A5 have a correlation of 1 -> discard A5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef790ed1-ae11-4067-9245-dea5adce94c1",
   "metadata": {},
   "source": [
    "A6 and A7 have a correlation of 0.57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30ff9c-cfd9-4afe-ac9a-49f240f17676",
   "metadata": {},
   "source": [
    "A9 and A16 (target) have a correlation of .72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2883ab-19f0-4530-8fea-2e5319b1edb0",
   "metadata": {},
   "source": [
    "## univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5b6e3-8b4e-4943-af37-dee29b3ca34c",
   "metadata": {},
   "source": [
    "A1 binary, 12 missing values\n",
    "replace missing values with most frequent category (b)\n",
    "\n",
    "A2 continuous, 12 missing values\n",
    "replace missing values with median\n",
    "\n",
    "A3 let be\n",
    "\n",
    "A4 trinary, 6 missing values\n",
    "summarize categories y and l to 'not-u' category, replace missing valuses with most frequent\n",
    "\n",
    "A5 discarded, correlation of 1 with A4\n",
    "\n",
    "A6 realtively uniformly disributed over 13 categories, not really sure what to do\n",
    "maybe discard, because correlated by >.5 with A7\n",
    "(maybe PCA with A7) (alternatively: frequency encode)\n",
    "\n",
    "A7 9 categries\n",
    "summarise to categories v, h, 'not-v-or-h', encode missing values as most frequent\n",
    "\n",
    "A8 let be\n",
    "\n",
    "A9 let be (note: highly correlated with target)\n",
    "\n",
    "A10 let be\n",
    "\n",
    "A11 continuous, replace 67 and 40 with median\n",
    "(maybe bin to null and not null)\n",
    "\n",
    "A12 let be\n",
    "\n",
    "A13 summarise to g and not-g\n",
    "\n",
    "A14 replace 2000 with median (maybe bin into a more-than-500-feature), replace with median\n",
    "\n",
    "A15 encode a null and not-null\n",
    "\n",
    "A16 let be\n",
    "\n",
    "mim-max scale continuious variables\n",
    "onehot en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223822d-ecb5-4708-a541-b861d2c2e907",
   "metadata": {},
   "source": [
    "# data preprocessing\n",
    "baseline classifier: 82% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0228314-609c-4470-abe2-cae1d16dc4b9",
   "metadata": {},
   "source": [
    "## train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d3755-c367-40bc-aa68-3c17c0cf9a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33)\n",
    "\n",
    "\n",
    "# further split test into test and validation set\n",
    "X_train_actual, X_valid, y_train_actual, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.15, random_state=42, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759f12c-30fc-4e42-8f79-31906daa18cc",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e25aed-b4d3-4519-b8f4-6367a7792ecb",
   "metadata": {},
   "source": [
    "do stuff from EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb033dd-5d62-4a45-875d-05f7584ddee2",
   "metadata": {},
   "source": [
    "evaluate feature engineering effectiveness by comparing classifier performance wth and without transformations applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e399e2-86cb-4888-bee2-48e9ed7172e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng_transformer = make_column_transformer(\n",
    "    (\n",
    "       make_pipeline(\n",
    "           SimpleImputer(strategy='most_frequent'),\n",
    "           OneHotEncoder(drop=\"first\")\n",
    "       ),\n",
    "        ['A1']\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "       make_pipeline(\n",
    "           SimpleImputer(strategy='median'),\n",
    "       ),\n",
    "        ['A2']\n",
    "    ),\n",
    "    # A5\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a748440-5f94-4775-a287-2cc275817eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef6559a-2d78-4198-b40b-8a9af45f936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.A4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92231944-e712-45a2-aa93-0a8bdc61829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    FunctionTransformer(lambda col: map(lambda e: 'u' if e == 'u' else 'n',col))\n",
    ")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ad5af-f17d-404b-9095-21c4b59fcde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X.A4.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6faf8fd-a943-4263-981d-004c6fe3d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pipe.fit_transform(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68908ff-d26b-4e13-bdef-3358bc75f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df18ced-5720-4d79-8d93-848e54c1d1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be0d256-2adf-4773-a709-a234305a88a4",
   "metadata": {},
   "source": [
    "r = pipe.fit_transform(data)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569d102-d202-4ce6-a9f8-fe0dacd4ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392efc5-0ef9-477e-95dc-ad05f2699399",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng_transformer = make_column_transformer(\n",
    "    (\n",
    "       make_pipeline(\n",
    "           SimpleImputer(strategy='most_frequent'),\n",
    "           OneHotEncoder(drop='first', categories=[('u'),('y'),('l')]),\n",
    "       ),\n",
    "        ['A4']\n",
    "    ),\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654f0f9-ae5c-42c7-a827-33eccb160eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9deefe-f050-4004-8d83-92e0f2042abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_pipeline =   make_column_transformer(\n",
    "    # categorical\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False),\n",
    "        ),\n",
    "        credit_approval.variables[(credit_approval.variables.type=='Categorical') & (credit_approval.variables.role =='Feature')].name.values\n",
    "    ),\n",
    "    # continuous\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"median\"), MinMaxScaler()\n",
    "        ),\n",
    "        credit_approval.variables[credit_approval.variables.type=='Continuous'].name.values\n",
    "    ),\n",
    "    remainder=\"passhrough\",\n",
    "    verbose=True,\n",
    "    verbose_feature_names_out=True,\n",
    ")\n",
    "cca_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e0225-31d8-4684-a73f-a5f05323aaa8",
   "metadata": {},
   "source": [
    "### PCA of A6 and A7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b3a55-8ae9-4b05-8dfa-1ba139e8a63c",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0a0ce-13f7-4d4d-94c1-9f0047508547",
   "metadata": {},
   "source": [
    "### Varianzanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e251c0-8389-43ba-a821-c1cb30f9748a",
   "metadata": {},
   "source": [
    "### Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59e686-edec-4b08-8e22-a5cd1ac0f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier(n_estimators=2, random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=clone(estimator),\n",
    "    n_features_to_select=15,\n",
    "    direction=\"forward\",\n",
    "    scoring=make_scorer(accuracy_score),\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    ").fit(df_train_actual, y_train_actual)\n",
    "\n",
    "sfs_custom = custom_feature_selection.SequentialFeatureSelector(\n",
    "    estimator=clone(estimator),\n",
    "    n_features_to_select=15,\n",
    "    scorer=make_scorer(accuracy_score),\n",
    "    direction=\"forward\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    ").fit(df_train_actual, y_train_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b890a26-7c94-453b-9a3d-302edb4ea937",
   "metadata": {
    "id": "9b890a26-7c94-453b-9a3d-302edb4ea937",
    "tags": []
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bdc72-042e-41fc-986f-6a2330591cba",
   "metadata": {
    "executionInfo": {
     "elapsed": 1829,
     "status": "aborted",
     "timestamp": 1702555193145,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "4e5bdc72-042e-41fc-986f-6a2330591cba"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combining categorial / numerical data:\n",
    "- Seperate classifiers, e.g. decicion tree + regressor\n",
    "- Encoding of categorical data.\n",
    "\n",
    "\n",
    "Feature Engineering:\n",
    "- Binarising highly imbalanced features\n",
    "- Introducing \"unknown\" category for missing values\n",
    "- Summarise categories\n",
    "- Binning continuous variables\n",
    "- Frequency encoding\n",
    "- Target encoding\n",
    "\n",
    "\n",
    "Machine Learning Models:\n",
    "- LogisticRegression\n",
    "- RandomForest (incl. missing values support)\n",
    "- LightGBM\n",
    "- XGBoost (doesn't work, also not in lecture script 02.3)\n",
    "- LinearSupportVectorClassifier\n",
    "\n",
    "Feature selection:\n",
    "- Forward / backward feature selection\n",
    "- Recursive / sequential feature selection\n",
    "\n",
    "\n",
    "Compare\n",
    "- LinearSVC vs SVC vs Adaboost\n",
    "\n",
    "\n",
    "Metrics:\n",
    "- Cross validation\n",
    "- Model evaluation metrics (FDR, TPR), precicion/recall, ROC_AUC\n",
    "- Graphics were all models are in comparison\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b2323-df90-4653-a641-5e1715914ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Index\n",
    "\n",
    "EDA\n",
    " encoding\n",
    " split\n",
    " PCA\n",
    " Dimension reduction\n",
    "Classifier\n",
    "Hyperparameter tuning\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d3e95-e28a-47e1-9649-f3c0daa524ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_pipeline = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        # categorical\n",
    "        (\n",
    "            make_pipeline(\n",
    "                SimpleImputer(strategy=\"most_frequent\"),\n",
    "                OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False),\n",
    "            ),\n",
    "            credit_approval.variables[(credit_approval.variables.type=='Categorical') & (credit_approval.variables.role =='Feature')].name.values\n",
    "        ),\n",
    "        # continuous\n",
    "        (\n",
    "            make_pipeline(\n",
    "                SimpleImputer(strategy=\"median\"), MinMaxScaler()\n",
    "            ),\n",
    "            credit_approval.variables[credit_approval.variables.type=='Continuous'].name.values\n",
    "        ),\n",
    "        remainder=\"passhrough\",\n",
    "        verbose=True,\n",
    "        verbose_feature_names_out=True,\n",
    "    ),\n",
    "    #xgb.XGBRegressor(),#objective=\"reg:linear\", random_state=42),\n",
    "    LogisticRegression(max_iter=100_000),\n",
    ")\n",
    "cca_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431c73e-172a-43a8-9879-dcc554803319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aktueller Stand\n",
    "\n",
    "XGBoost funktioniert irgendwie nicht mit den aktuellen Datentypen, deshalb habe ich erstmal noch die LogisticRegression in die Pipeline gepackt.\n",
    "\n",
    "Mit der Logistic Regression bekommt man auch die untenstehende Warning, dass einige unknown Kategorien weiterhin als Zeros encoded werden. Das ist seltsam,\n",
    "da der Simple Imputer eigentlich daf√ºr sorgen sollte, das keine unknown Categories mehr in den daten sind (sondern diese alle durch die most frequent category ersetzt werden).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71294a-2d82-4b02-bc2f-9f68f592892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(\n",
    "    estimator=cca_pipeline,\n",
    "    X=X_train_actual,\n",
    "    y=y_train_actual.values.ravel(), \n",
    "    cv=StratifiedKFold(n_splits=7, shuffle=True, random_state=42),\n",
    "    scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26271ac0-e432-4d68-a9a4-4330a547bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cca = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = run_cv(\n",
    "    cca_transform_xgb,\n",
    "    X_train_actual,\n",
    "    y_train_actual.replace({'-': 1, '+': 0}),\n",
    "    cv=cv_cca,\n",
    ")\n",
    "print_test_scores(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904fb2e-de9f-4c3a-81ef-bb8c9de30ee4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a678a0-4d14-47f4-9331-5f19fb010f64",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1702555193882,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "82a678a0-4d14-47f4-9331-5f19fb010f64"
   },
   "outputs": [],
   "source": [
    "pipe=Pipeline(\n",
    "    steps = [\n",
    "        #(\"encoder\", ce.OneHotEncoder()),\n",
    "        ('xgb', xgb.XGBRegressor(objective=\"reg:linear\", random_state=42))\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c9d24-1a24-4666-9002-94fb8e054d17",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1702555193882,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "749c9d24-1a24-4666-9002-94fb8e054d17"
   },
   "outputs": [],
   "source": [
    "X = credit_approval.data.features\n",
    "y = targets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33)#, random_state=42)\n",
    "\n",
    "\n",
    "#xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n",
    "\n",
    "pipe.fit(X_train._get_numeric_data(), y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test._get_numeric_data())\n",
    "\n",
    "mse=mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95314d8b-9145-4f5c-afbd-7c9e3994de8e",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1702555193882,
     "user": {
      "displayName": "Diana Wei√üleder",
      "userId": "00551999898217696741"
     },
     "user_tz": -60
    },
    "id": "95314d8b-9145-4f5c-afbd-7c9e3994de8e"
   },
   "outputs": [],
   "source": [
    "1-mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83bf48-13a4-417c-b94e-243a40af4d97",
   "metadata": {},
   "source": [
    "## model evalutation"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
